#include <cmath>
#include <iostream>
#include "gpu-new-forward.h"

// ./rai -p ece408_project --queue rai_amd64_ece408

#define TILE_WIDTH 16

#define TILE_WIDTH_K 32
#define TILE_WIDTH_X 16
// #define TILE_WIDTH_RATIO (TILE_WIDTH_K / TILE_WIDTH_X)
#define TILE_WIDTH_RATIO 2

__constant__ float const_k[3136];

__global__ void conv_forward_kernel(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    /*
    Modify this function to implement the forward pass described in Chapter 16.
    We have added an additional dimension to the tensors to support an entire mini-batch
    The goal here is to be correct AND fast.

    Function paramter definitions:
    y - output
    x - input
    k - kernel
    B - batch_size (number of images in x)
    M - number of output feature maps
    C - number of input feature maps
    H - input height dimension
    W - input width dimension
    K - kernel height and width (K x K)
    */

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;
    (void)H_out; // silence declared but never referenced warning. remove this line when you start working
    (void)W_out; // silence declared but never referenced warning. remove this line when you start working

    // We have some nice #defs for you below to simplify indexing. Feel free to use them, or create your own.
    // An example use of these macros:
    // float a = y4d(0,0,0,0)
    // y4d(0,0,0,0) = a

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    // Insert your GPU convolution kernel code here

    int W_grid = ceil(1.0 * W_out / TILE_WIDTH);
    int m = blockIdx.x;
    int h = (blockIdx.y / W_grid) * TILE_WIDTH + threadIdx.y;
    int w = (blockIdx.y % W_grid) * TILE_WIDTH + threadIdx.x;

    if (h < H_out && w < W_out) {
        for (int b = 0; b < B; b++) {
            float acc = 0.0f;
            for (int c = 0; c < C; c++) {
                for (int p = 0; p < K; p++) {
                    for (int q = 0; q < K; q++) {
                        acc += x4d(b, c, h + p, w + q) * k4d(m, c, p, q);
                    }
                }
            }
            y4d(b, m, h, w) = acc;
        }
    }
   

#undef y4d
#undef x4d
#undef k4d
}

__global__ void unroll_x(const float *x, float *x_unroll, const int B, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    int bx = blockIdx.x, tx = threadIdx.x;
    int by = blockIdx.y, ty = threadIdx.y;
    
    int h = bx / W_out + ty;
    int w = bx % W_out + tx;
    int c = by;
    int h_unroll = c * K * K + ty * K + tx;
    int w_unroll = bx;

#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define xu3d(i2, i1, i0)    x_unroll[(i2) * (C * K * K * H_out * W_out) + (i1) * (H_out * W_out) + i0]

    for (int b = 0; b < B; b++) {
        xu3d(b, h_unroll, w_unroll) = x4d(b, c, h, w);
    }

#undef x4d
#undef xu3d
}

__global__ void unroll_k(const float *k, float *k_unroll, const int B, const int C, const int H, const int W, const int K)
{
    int bx = blockIdx.x, tx = threadIdx.x;
    int by = blockIdx.y, ty = threadIdx.y;
    
    int h = ty;
    int w = tx;
    int m = by;
    int c = bx;
    int h_unroll = m;
    int w_unroll = c * K * K + ty * K + tx;

#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]
#define ku2d(i1, i0)        k_unroll[(i1) * (C * K * K) + i0]

    ku2d(h_unroll, w_unroll) = k4d(m, c, h, w);

#undef k4d
#undef ku2d
}

__global__ void basicMatrixMultiply(float *y, float *x_unroll, float *k_unroll, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    int r = blockIdx.y * blockDim.y + threadIdx.y;
    int c = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define xu3d(i2, i1, i0)    x_unroll[(i2) * (C * K * K * H_out * W_out) + (i1) * (H_out * W_out) + i0]
#define ku2d(i1, i0)        k_unroll[(i1) * (C * K * K) + i0]

    if (r < M && c < xuCol) {
        for (int b = 0; b < B; b++) {
            float acc = 0.0f;

            for (int i = 0; i < xuRow; i++) {
                acc += ku2d(r, i) * xu3d(b, i, c);
            }

            y4d(b, r, c / W_out, c % W_out) = acc;
        }
    }

#undef y4d
#undef xu3d
#undef ku2d
}

__global__ void tiledMatrixMultiply(float *y, float *x_unroll, float *k_unroll, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int r = blockIdx.y * blockDim.y + threadIdx.y;
    int c = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define xu3d(i2, i1, i0)    x_unroll[(i2) * (C * K * K * H_out * W_out) + (i1) * (H_out * W_out) + i0]
#define ku2d(i1, i0)        k_unroll[(i1) * (C * K * K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {
            if (r < M && q * TILE_WIDTH + tx < xuRow) {
                subTileK[ty][tx] = ku2d(r, q * TILE_WIDTH + tx);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            if (q * TILE_WIDTH + ty < xuRow && c < xuCol) {
                subTileX[ty][tx] = xu3d(b, q * TILE_WIDTH + ty, c);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (r < M && c < xuCol) {
                for (int k = 0; k < TILE_WIDTH; k++) {
                    acc += subTileK[ty][k] * subTileX[k][tx];
                }
            }
        
            __syncthreads();
        }

        if (r < M && c < xuCol) {
            y4d(b, r, c / W_out, c % W_out) = acc;
        }
    }

#undef y4d
#undef xu3d
#undef ku2d
}

__global__ void unrollTiledMatrixMultiply(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_c = q * TILE_WIDTH + tx;
            int ck = tile_c / (K * K);
            int k_remain = tile_c % (K * K);
            int hk = k_remain / K;
            int wk = k_remain % K;

            if (row < M && tile_c < xuRow) {
                subTileK[ty][tx] = k4d(m, ck, hk, wk);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {
                    acc += subTileK[ty][i] * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void constUnrollTiledMatrixMultiply(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) const_k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            int k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {

                    int tile_c = q * TILE_WIDTH + i;
                    int ck = tile_c / (K * K);
                    k_remain = tile_c % (K * K);
                    int hk = k_remain / K;
                    int wk = k_remain % K;

                    acc += k4d(m, ck, hk, wk) * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void constUnrollTiledMatrixMultiply2(float *y, const float *x, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) const_k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_c = q * TILE_WIDTH + tx;
            int ck = tile_c / (K * K);
            int k_remain = tile_c % (K * K);
            int hk = k_remain / K;
            int wk = k_remain % K;

            if (row < M && tile_c < xuRow) {
                subTileK[ty][tx] = k4d(m, ck, hk, wk);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {
                    acc += subTileK[ty][i] * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void jointUnrollTiledMatrixMultiply(float *__restrict__ y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileX[TILE_WIDTH_RATIO][TILE_WIDTH_X];

    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x;

    int row = bx * blockDim.x + tx;
    int col = by * TILE_WIDTH_X;

    float y_reg[TILE_WIDTH_X];

    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = (xuCol - 1) / TILE_WIDTH_RATIO + 1;

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            y_reg[outIdx] = 0;
        }

        for (int q = 0; q < iter; q++) {

            int i = tx / TILE_WIDTH_X;
            int j = tx % TILE_WIDTH_X;

            int tile_r = q * TILE_WIDTH_RATIO + i;
            int tile_c = col + j;
            int cx = tile_r / (K * K);
            int k_remain = tile_r % (K * K);
            int hx = tile_c / W_out + k_remain / K;
            int wx = tile_c % W_out + k_remain % K;

            if (tile_r < xuRow && tile_c < xuCol) {
                subTileX[i][j] = x4d(b, cx, hx, wx);
            } else {
                subTileX[i][j] = 0.0f;
            }

            __syncthreads();


            for (int idx = 0; idx < TILE_WIDTH_RATIO; idx++) {
                float k_reg;

                tile_c = q * TILE_WIDTH_RATIO + idx;
                int ck = tile_c / (K * K);
                k_remain = tile_c % (K * K);
                int hk = k_remain / K;
                int wk = k_remain % K;

                if (row < M && tile_c < xuRow) {
                    k_reg = k4d(m, ck, hk, wk);
                } else {
                    k_reg = 0.0f;
                }

                for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
                    y_reg[outIdx] += k_reg * subTileX[idx][outIdx];
                }
            }
        
            __syncthreads();
        }

        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            int outCol = col + outIdx;
            if (row < M && outCol < xuCol) {
                y4d(b, row, outCol / W_out, outCol % W_out) = y_reg[outIdx];
            }
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void unrollTiledMatrixMultiply2(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;
    int b = blockIdx.z;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    // if (b < B) {
    // for (int b = blockIdx.z * blockDim.z; b < B; b += blockDim.z) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_c = q * TILE_WIDTH + tx;
            int ck = tile_c / (K * K);
            int k_remain = tile_c % (K * K);
            int hk = k_remain / K;
            int wk = k_remain % K;

            if (row < M && tile_c < xuRow) {
                subTileK[ty][tx] = k4d(m, ck, hk, wk);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {
                    acc += subTileK[ty][i] * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    // }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void jointUnrollTiledMatrixMultiply2(float *__restrict__ y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileX[TILE_WIDTH_RATIO][TILE_WIDTH_X];

    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x;

    int row = bx * blockDim.x + tx;
    int col = by * TILE_WIDTH_X;

    float y_reg[TILE_WIDTH_X];

    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = (xuCol - 1) / TILE_WIDTH_RATIO + 1;

    int m = row;
    int b = blockIdx.z;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    // for (int b = 0; b < B; b++) {
        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            y_reg[outIdx] = 0;
        }

        for (int q = 0; q < iter; q++) {

            int i = tx / TILE_WIDTH_X;
            int j = tx % TILE_WIDTH_X;

            int tile_r = q * TILE_WIDTH_RATIO + i;
            int tile_c = col + j;
            int cx = tile_r / (K * K);
            int k_remain = tile_r % (K * K);
            int hx = tile_c / W_out + k_remain / K;
            int wx = tile_c % W_out + k_remain % K;

            if (tile_r < xuRow && tile_c < xuCol) {
                subTileX[i][j] = x4d(b, cx, hx, wx);
            } else {
                subTileX[i][j] = 0.0f;
            }

            __syncthreads();


            for (int idx = 0; idx < TILE_WIDTH_RATIO; idx++) {
                float k_reg;

                tile_c = q * TILE_WIDTH_RATIO + idx;
                int ck = tile_c / (K * K);
                k_remain = tile_c % (K * K);
                int hk = k_remain / K;
                int wk = k_remain % K;

                if (row < M && tile_c < xuRow) {
                    k_reg = k4d(m, ck, hk, wk);
                } else {
                    k_reg = 0.0f;
                }

                for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
                    y_reg[outIdx] += k_reg * subTileX[idx][outIdx];
                }
            }
        
            __syncthreads();
        }

        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            int outCol = col + outIdx;
            if (row < M && outCol < xuCol) {
                y4d(b, row, outCol / W_out, outCol % W_out) = y_reg[outIdx];
            }
        }
    // }

#undef y4d
#undef x4d
#undef k4d
}

__host__ void GPUInterface::conv_forward_gpu_prolog(const float *host_y, const float *host_x, const float *host_k, float **device_y_ptr, float **device_x_ptr, float **device_k_ptr, const int B, const int M, const int C, const int H, const int W, const int K)
{
    // Allocate memory and copy over the relevant data structures to the GPU

    // We pass double pointers for you to initialize the relevant device pointers,
    //  which are passed to the other two functions.

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    const int sizeY = B * M * H_out * W_out * sizeof(float);
    const int sizeX = B * C * H * W * sizeof(float);
    const int sizeK = C * M * K * K * sizeof(float);

    cudaMalloc((void **)device_y_ptr, sizeY);
    cudaMalloc((void **)device_x_ptr, sizeX);
    cudaMalloc((void **)device_k_ptr, sizeK);

    cudaMemcpy(*device_x_ptr, host_x, sizeX, cudaMemcpyHostToDevice);
    cudaMemcpy(*device_k_ptr, host_k, sizeK, cudaMemcpyHostToDevice);
    // cudaMemcpyToSymbol(const_k, host_k, sizeK);

    // Useful snippet for error checking
    // cudaError_t error = cudaGetLastError();
    // if(error != cudaSuccess)
    // {
    //     std::cout<<"CUDA error: "<<cudaGetErrorString(error)<<std::endl;
    //     exit(-1);
    // }

}


__host__ void GPUInterface::conv_forward_gpu(float *device_y, const float *device_x, const float *device_k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    // Set the kernel dimensions and call the kernel

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    // float *device_x_unroll;
    // float *device_k_unroll;

    // cudaMalloc((void **) &device_x_unroll, B * (C * K * K) * (H_out * W_out) * sizeof(float));
    // cudaMalloc((void **) &device_k_unroll, M * (C * K * K) * sizeof(float));

    /*
     *  Unroll X matrix
     */

    // dim3 dimGrid_x(H_out * W_out, C, 1);
    // dim3 dimBlock_x(K, K, 1);

    // unroll_x<<<dimGrid_x, dimBlock_x>>>(device_x, device_x_unroll, B, C, H, W, K);


    /*
     *  Unroll K matrix
     */

    // dim3 dimGrid_k(C, M, 1);
    // dim3 dimBlock_k(K, K, 1);

    // unroll_k<<<dimGrid_k, dimBlock_k>>>(device_k, device_k_unroll, B, C, H, W, K);

    /*
     *  Basic Matrix Multiply
     */

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // basicMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x_unroll, device_k_unroll, B, M, C, H, W, K);

    /*
     *  Tiled Matrix Multiply
     */

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // tiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x_unroll, device_k_unroll, B, M, C, H, W, K);


    /*
     *  PM2 Basic Convolution
     */

    // const int W_grid = ceil(1.0 * W_out / TILE_WIDTH);
    // const int H_grid = ceil(1.0 * H_out / TILE_WIDTH);
    // const int Y = H_grid * W_grid;


    // dim3 dimGrid(M, Y, 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // conv_forward_kernel<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);


    /*
     *  Kernel Fusion Tiled Matrix Multiply
     */

    // printf("B: %d, M: %d, C: %d, H: %d, W: %d, K: %d\n\n", B, M, C, H, W, K);

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // unrollTiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);

    // constUnrollTiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);

    // constUnrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, B, M, C, H, W, K);

    // dim3 dimGrid( (M + TILE_WIDTH_K - 1) / TILE_WIDTH_K, (H_out * W_out + TILE_WIDTH_X - 1) / TILE_WIDTH_X, 1);
    // dim3 dimBlock(TILE_WIDTH_K, 1, 1);

    // jointUnrollTiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);


    /*
     *  Kernel Fusion Tiled Matrix Multiply + Parallel B
     */

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), B);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // unrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);







    dim3 dimGrid( (M + TILE_WIDTH_K - 1) / TILE_WIDTH_K, (H_out * W_out + TILE_WIDTH_X - 1) / TILE_WIDTH_X, B);
    dim3 dimBlock(TILE_WIDTH_K, 1, 1);

    jointUnrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);


    // cudaFree(device_x_unroll);
    // cudaFree(device_k_unroll);
}


__host__ void GPUInterface::conv_forward_gpu_epilog(float *host_y, float *device_y, float *device_x, float *device_k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    // Copy the output back to host

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    const int sizeY = B * M * H_out * W_out * sizeof(float);

    cudaMemcpy(host_y, device_y, sizeY, cudaMemcpyDeviceToHost);

    // Free device memory

    cudaFree(device_y);
    cudaFree(device_x);
    cudaFree(device_k);
}


__host__ void GPUInterface::get_device_properties()
{
    int deviceCount;
    cudaGetDeviceCount(&deviceCount);

    for(int dev = 0; dev < deviceCount; dev++)
    {
        cudaDeviceProp deviceProp;
        cudaGetDeviceProperties(&deviceProp, dev);

        std::cout<<"Device "<<dev<<" name: "<<deviceProp.name<<std::endl;
        std::cout<<"Computational capabilities: "<<deviceProp.major<<"."<<deviceProp.minor<<std::endl;
        std::cout<<"Max Global memory size: "<<deviceProp.totalGlobalMem<<std::endl;
        std::cout<<"Max Constant memory size: "<<deviceProp.totalConstMem<<std::endl;
        std::cout<<"Max Shared memory size per block: "<<deviceProp.sharedMemPerBlock<<std::endl;
        std::cout<<"Max threads per block: "<<deviceProp.maxThreadsPerBlock<<std::endl;
        std::cout<<"Max block dimensions: "<<deviceProp.maxThreadsDim[0]<<" x, "<<deviceProp.maxThreadsDim[1]<<" y, "<<deviceProp.maxThreadsDim[2]<<" z"<<std::endl;
        std::cout<<"Max grid dimensions: "<<deviceProp.maxGridSize[0]<<" x, "<<deviceProp.maxGridSize[1]<<" y, "<<deviceProp.maxGridSize[2]<<" z"<<std::endl;
        std::cout<<"Warp Size: "<<deviceProp.warpSize<<std::endl;
    }
}
