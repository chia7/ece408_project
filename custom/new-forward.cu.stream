#include <cmath>
#include <iostream>
#include "gpu-new-forward.h"

// ./rai -p ece408_project --queue rai_amd64_ece408

#define TILE_WIDTH 16

#define TILE_WIDTH_K 256
#define TILE_WIDTH_X 16
// #define TILE_WIDTH_RATIO (TILE_WIDTH_K / TILE_WIDTH_X)
#define TILE_WIDTH_RATIO 16

__constant__ float const_k[3136];


#define PARTITION 4
float *kDev[PARTITION], *xDev[PARTITION], *yDev[PARTITION][PARTITION];
cudaStream_t copyStream[2], kernelStream;


cudaEvent_t waitKX[2 * PARTITION - 1], waitY[PARTITION][PARTITION];

__global__ void unrollTiledMatrixMultiply(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_c = q * TILE_WIDTH + tx;
            int ck = tile_c / (K * K);
            int k_remain = tile_c % (K * K);
            int hk = k_remain / K;
            int wk = k_remain % K;

            if (row < M && tile_c < xuRow) {
                subTileK[ty][tx] = k4d(m, ck, hk, wk);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {
                    acc += subTileK[ty][i] * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void constUnrollTiledMatrixMultiply(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) const_k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            int k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {

                    int tile_c = q * TILE_WIDTH + i;
                    int ck = tile_c / (K * K);
                    k_remain = tile_c % (K * K);
                    int hk = k_remain / K;
                    int wk = k_remain % K;

                    acc += k4d(m, ck, hk, wk) * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void constUnrollTiledMatrixMultiply2(float *y, const float *x, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) const_k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_c = q * TILE_WIDTH + tx;
            int ck = tile_c / (K * K);
            int k_remain = tile_c % (K * K);
            int hk = k_remain / K;
            int wk = k_remain % K;

            if (row < M && tile_c < xuRow) {
                subTileK[ty][tx] = k4d(m, ck, hk, wk);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {
                    acc += subTileK[ty][i] * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void jointUnrollTiledMatrixMultiply(float *__restrict__ y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileX[TILE_WIDTH_RATIO][TILE_WIDTH_X];

    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x;

    int row = bx * blockDim.x + tx;
    int col = by * TILE_WIDTH_X;

    float y_reg[TILE_WIDTH_X];

    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = (xuCol - 1) / TILE_WIDTH_RATIO + 1;

    int m = row;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    for (int b = 0; b < B; b++) {
        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            y_reg[outIdx] = 0;
        }

        for (int q = 0; q < iter; q++) {

            int i = tx / TILE_WIDTH_X;
            int j = tx % TILE_WIDTH_X;

            int tile_r = q * TILE_WIDTH_RATIO + i;
            int tile_c = col + j;
            int cx = tile_r / (K * K);
            int k_remain = tile_r % (K * K);
            int hx = tile_c / W_out + k_remain / K;
            int wx = tile_c % W_out + k_remain % K;

            if (tile_r < xuRow && tile_c < xuCol) {
                subTileX[i][j] = x4d(b, cx, hx, wx);
            } else {
                subTileX[i][j] = 0.0f;
            }

            __syncthreads();


            for (int idx = 0; idx < TILE_WIDTH_RATIO; idx++) {
                float k_reg;

                tile_c = q * TILE_WIDTH_RATIO + idx;
                int ck = tile_c / (K * K);
                k_remain = tile_c % (K * K);
                int hk = k_remain / K;
                int wk = k_remain % K;

                if (row < M && tile_c < xuRow) {
                    k_reg = k4d(m, ck, hk, wk);
                } else {
                    k_reg = 0.0f;
                }

                for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
                    y_reg[outIdx] += k_reg * subTileX[idx][outIdx];
                }
            }
        
            __syncthreads();
        }

        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            int outCol = col + outIdx;
            if (row < M && outCol < xuCol) {
                y4d(b, row, outCol / W_out, outCol % W_out) = y_reg[outIdx];
            }
        }
    }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void unrollTiledMatrixMultiply2(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;
    int b = blockIdx.z;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    // if (b < B) {
    // for (int b = blockIdx.z * blockDim.z; b < B; b += blockDim.z) {
        float acc = 0.0f;

        for (int q = 0; q < iter; q++) {

            int tile_c = q * TILE_WIDTH + tx;
            int ck = tile_c / (K * K);
            int k_remain = tile_c % (K * K);
            int hk = k_remain / K;
            int wk = k_remain % K;

            if (row < M && tile_c < xuRow) {
                subTileK[ty][tx] = k4d(m, ck, hk, wk);
            } else {
                subTileK[ty][tx] = 0.0f;
            }

            int tile_r = q * TILE_WIDTH + ty;
            int cx = tile_r / (K * K);
            k_remain = tile_r % (K * K);
            int hx = col / W_out + k_remain / K;
            int wx = col % W_out + k_remain % K;

            if (tile_r < xuRow && col < xuCol) {
                subTileX[ty][tx] = x4d(b, cx, hx, wx);
            } else {
                subTileX[ty][tx] = 0.0f;
            }

            __syncthreads();
    
            if (row < M && col < xuCol) {
                for (int i = 0; i < TILE_WIDTH; i++) {
                    acc += subTileK[ty][i] * subTileX[i][tx];
                }
            }
        
            __syncthreads();
        }

        if (row < M && col < xuCol) {
            y4d(b, row, col / W_out, col % W_out) = acc;
        }
    // }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void jointUnrollTiledMatrixMultiply2(float *__restrict__ y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileX[TILE_WIDTH_RATIO][TILE_WIDTH_X];

    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x;

    int row = bx * blockDim.x + tx;
    int col = by * TILE_WIDTH_X;

    float y_reg[TILE_WIDTH_X];

    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = (xuCol - 1) / TILE_WIDTH_RATIO + 1;

    int m = row;
    int b = blockIdx.z;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    // for (int b = 0; b < B; b++) {
        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            y_reg[outIdx] = 0;
        }

        for (int q = 0; q < iter; q++) {

            int i = tx / TILE_WIDTH_X;
            int j = tx % TILE_WIDTH_X;

            int tile_r = q * TILE_WIDTH_RATIO + i;
            int tile_c = col + j;
            int cx = tile_r / (K * K);
            int k_remain = tile_r % (K * K);
            int hx = tile_c / W_out + k_remain / K;
            int wx = tile_c % W_out + k_remain % K;

            if (tile_r < xuRow && tile_c < xuCol) {
                subTileX[i][j] = x4d(b, cx, hx, wx);
            } else {
                subTileX[i][j] = 0.0f;
            }

            __syncthreads();


            for (int idx = 0; idx < TILE_WIDTH_RATIO; idx++) {
                float k_reg;

                tile_c = q * TILE_WIDTH_RATIO + idx;
                int ck = tile_c / (K * K);
                k_remain = tile_c % (K * K);
                int hk = k_remain / K;
                int wk = k_remain % K;

                if (row < M && tile_c < xuRow) {
                    k_reg = k4d(m, ck, hk, wk);
                } else {
                    k_reg = 0.0f;
                }

                for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
                    y_reg[outIdx] += k_reg * subTileX[idx][outIdx];
                }
            }
        
            __syncthreads();
        }

        for (int outIdx = 0; outIdx < TILE_WIDTH_X; outIdx++) {
            int outCol = col + outIdx;
            if (row < M && outCol < xuCol) {
                y4d(b, row, outCol / W_out, outCol % W_out) = y_reg[outIdx];
            }
        }
    // }

#undef y4d
#undef x4d
#undef k4d
}

__global__ void unrollTiledMatrixMultiply3(float *y, const float *x, const float *k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    __shared__ float subTileK[TILE_WIDTH][TILE_WIDTH];
    __shared__ float subTileX[TILE_WIDTH][TILE_WIDTH];

    // int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int xuRow = C * K * K;
    int xuCol = H_out * W_out;

    int iter = ceil(1.0 * xuRow / TILE_WIDTH);

    int m = row;
    int b = blockIdx.z;

#define y4d(i3, i2, i1, i0) y[(i3) * (M * H_out * W_out) + (i2) * (H_out * W_out) + (i1) * (W_out) + i0]
#define x4d(i3, i2, i1, i0) x[(i3) * (C * H * W) + (i2) * (H * W) + (i1) * (W) + i0]
#define k4d(i3, i2, i1, i0) k[(i3) * (C * K * K) + (i2) * (K * K) + (i1) * (K) + i0]

    float acc = 0.0f;

    for (int q = 0; q < iter; q++) {

        int tile_c = q * TILE_WIDTH + tx;
        int ck = tile_c / (K * K);
        int k_remain = tile_c % (K * K);
        int hk = k_remain / K;
        int wk = k_remain % K;

        if (row < M && tile_c < xuRow) {
            subTileK[ty][tx] = k4d(m, ck, hk, wk);
        } else {
            subTileK[ty][tx] = 0.0f;
        }

        int tile_r = q * TILE_WIDTH + ty;
        int cx = tile_r / (K * K);
        k_remain = tile_r % (K * K);
        int hx = col / W_out + k_remain / K;
        int wx = col % W_out + k_remain % K;

        if (tile_r < xuRow && col < xuCol) {
            subTileX[ty][tx] = x4d(b, cx, hx, wx);
        } else {
            subTileX[ty][tx] = 0.0f;
        }

        __syncthreads();

        if (row < M && col < xuCol) {
            for (int i = 0; i < TILE_WIDTH; i++) {
                acc += subTileK[ty][i] * subTileX[i][tx];
            }
        }
    
        __syncthreads();
    }

    if (row < M && col < xuCol) {
        y4d(b, row, col / W_out, col % W_out) = acc;
    }


#undef y4d
#undef x4d
#undef k4d
}

__host__ void GPUInterface::conv_forward_gpu_prolog(const float *host_y, const float *host_x, const float *host_k, float **device_y_ptr, float **device_x_ptr, float **device_k_ptr, const int B, const int M, const int C, const int H, const int W, const int K)
{
    // Allocate memory and copy over the relevant data structures to the GPU

    // We pass double pointers for you to initialize the relevant device pointers,
    //  which are passed to the other two functions.

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    // const int sizeY = B * M * H_out * W_out * sizeof(float);
    // const int sizeX = B * C * H * W * sizeof(float);
    // const int sizeK = C * M * K * K * sizeof(float);

    // cudaMalloc((void **)device_y_ptr, sizeY);
    // cudaMalloc((void **)device_x_ptr, sizeX);
    // cudaMalloc((void **)device_k_ptr, sizeK);


    for (int i = 0; i < 2 * PARTITION - 1; i++) {
        cudaEventCreate(&waitKX[i]);
    }

    for (int i = 0; i < PARTITION; i++) {
        for (int j = 0; j < PARTITION; j++) {
            cudaEventCreate(&waitY[i][j]);
        }
    }


    const int sizeY = B * M / PARTITION * H_out * W_out / PARTITION * sizeof(float);
    const int sizeX = B * C * H * W / PARTITION * sizeof(float);
    const int sizeK = C * M / PARTITION * K * K * sizeof(float);

    for (int i = 0; i < PARTITION; i++) {
        cudaMalloc((void **)&xDev[i], sizeX);
        for (int j = 0; j < PARTITION; j++) {
            cudaMalloc((void **)&yDev[i][j], sizeY);
        }
        cudaMalloc((void **)&kDev[i], sizeK);
    }

    cudaStreamCreate(&copyStream[0]);
    cudaStreamCreate(&copyStream[1]);
    cudaStreamCreate(&kernelStream);


    int idx = 0;
    for (int i = 0; i < PARTITION; i++) {

        cudaMemcpyAsync(kDev[i], host_k + i * sizeK, sizeK, cudaMemcpyDefault, copyStream[0]);

        if (i == 0) {
            cudaEventRecord(waitKX[idx++], copyStream[0]);
        } else {
            cudaEventRecord(waitKX[idx++], kernelStream);
        }

        cudaMemcpyAsync(xDev[i], host_x + i * sizeX, sizeX, cudaMemcpyDefault, copyStream[0]);

        cudaEventRecord(waitKX[idx++], kernelStream);
    }

    // cudaMemcpy(*device_x_ptr, host_x, sizeX, cudaMemcpyHostToDevice);
    // cudaMemcpy(*device_k_ptr, host_k, sizeK, cudaMemcpyHostToDevice);

    // cudaMemcpyToSymbol(const_k, host_k, sizeK);

    // Useful snippet for error checking
    // cudaError_t error = cudaGetLastError();
    // if(error != cudaSuccess)
    // {
    //     std::cout<<"CUDA error: "<<cudaGetErrorString(error)<<std::endl;
    //     exit(-1);
    // }

}


__host__ void GPUInterface::conv_forward_gpu(float *device_y, const float *device_x, const float *device_k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    // Set the kernel dimensions and call the kernel

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    /*
     *  Tiled Matrix Multiply
     */

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // tiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x_unroll, device_k_unroll, B, M, C, H, W, K);


    /*
     *  PM2 Basic Convolution
     */

    // const int W_grid = ceil(1.0 * W_out / TILE_WIDTH);
    // const int H_grid = ceil(1.0 * H_out / TILE_WIDTH);
    // const int Y = H_grid * W_grid;


    // dim3 dimGrid(M, Y, 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // conv_forward_kernel<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);


    /*
     *  Kernel Fusion Tiled Matrix Multiply
     */

    printf("B: %d, M: %d, C: %d, H: %d, W: %d, K: %d, H_out: %d, W_out: %d\n\n", B, M, C, H, W, K, H_out, W_out);

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), 1);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // unrollTiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);

    // constUnrollTiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);

    // constUnrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, B, M, C, H, W, K);

    // dim3 dimGrid( (M + TILE_WIDTH_K - 1) / TILE_WIDTH_K, (H_out * W_out + TILE_WIDTH_X - 1) / TILE_WIDTH_X, 1);
    // dim3 dimBlock(TILE_WIDTH_K, 1, 1);

    // jointUnrollTiledMatrixMultiply<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);



    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), B);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // unrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);



    /*
     *  Kernel Fusion Tiled Matrix Multiply + Parallel B
     */

    // dim3 dimGrid(ceil(1.0 * H_out * W_out / TILE_WIDTH), ceil(1.0 * M / TILE_WIDTH), B);
    // dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // unrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);



    /*
     *  Kernel Fusion Register Tiled Matrix Multiply + Parallel B
     */

    // dim3 dimGrid( (M + TILE_WIDTH_K - 1) / TILE_WIDTH_K, (H_out * W_out + TILE_WIDTH_X - 1) / TILE_WIDTH_X, B);
    // dim3 dimBlock(TILE_WIDTH_K, 1, 1);

    // jointUnrollTiledMatrixMultiply2<<<dimGrid, dimBlock>>>(device_y, device_x, device_k, B, M, C, H, W, K);


    dim3 dimGrid(ceil(1.0 * H_out * W_out / PARTITION / TILE_WIDTH), ceil(1.0 * M / PARTITION / TILE_WIDTH), B);
    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);

    // const int sizeY = B * M / PARTITION * H_out * W_out / PARTITION * sizeof(float);
    // const int sizeX = B * C * H * W / PARTITION * sizeof(float);
    // const int sizeK = C * M / PARTITION * K * K * sizeof(float);


    int idx = 0;
    for (int i = 0; i < PARTITION; i++) {

        // cudaMemcpyAsync(kDev[i], host_k[i * sizeK], sizeK, cudaMemcpyDefault, copyStream[0]);

        for (int j = 0; j < PARTITION; j++) {
            // cudaMemcpyAsync(xDev[j], host_x[j * sizeX], sizeX, cudaMemcpyDefault, copyStream[0]);


            cudaStreamWaitEvent(kernelStream, waitKX[idx++], 0);
            unrollTiledMatrixMultiply2<<<dimGrid, dimBlock, 0, kernelStream>>>(yDev[i][j], xDev[j], kDev[i], B, M, C, H, W, K);

            cudaEventRecord(waitY[i][j], kernelStream);

            // cudaMemcpy(host_y[(i * PARTITION + j) * sizeY], yDev[i][j], sizeY, cudaMemcpyDeviceToHost, copyStream[1]);
        }
    }


    cudaDeviceSynchronize();
    cudaEventSynchronize(waitY[PARTITION - 1][PARTITION - 1]);

    // cudaFree(device_x_unroll);
    // cudaFree(device_k_unroll);
}


__host__ void GPUInterface::conv_forward_gpu_epilog(float *host_y, float *device_y, float *device_x, float *device_k, const int B, const int M, const int C, const int H, const int W, const int K)
{
    // Copy the output back to host

    const int H_out = H - K + 1;
    const int W_out = W - K + 1;

    // const int sizeY = B * M * H_out * W_out * sizeof(float);

    // cudaMemcpy(host_y, device_y, sizeY, cudaMemcpyDeviceToHost);


    const int sizeY = B * M / PARTITION * H_out * W_out / PARTITION * sizeof(float);

    for (int i = 0; i < PARTITION; i++) {

        for (int j = 0; j < PARTITION; j++) {

            cudaStreamWaitEvent(copyStream[1], waitY[i][j], 0);
            cudaMemcpyAsync(host_y + (i * PARTITION + j) * sizeY, yDev[i][j], sizeY, cudaMemcpyDeviceToHost, copyStream[1]);
        }
    }

    // cudaDeviceSynchronize();

    cudaDeviceSynchronize();
    cudaEventSynchronize(waitY[PARTITION - 1][PARTITION - 1]);

    // Free device memory

    cudaFree(device_y);
    cudaFree(device_x);
    cudaFree(device_k);
}


__host__ void GPUInterface::get_device_properties()
{
    int deviceCount;
    cudaGetDeviceCount(&deviceCount);

    for(int dev = 0; dev < deviceCount; dev++)
    {
        cudaDeviceProp deviceProp;
        cudaGetDeviceProperties(&deviceProp, dev);

        std::cout<<"Device "<<dev<<" name: "<<deviceProp.name<<std::endl;
        std::cout<<"Computational capabilities: "<<deviceProp.major<<"."<<deviceProp.minor<<std::endl;
        std::cout<<"Max Global memory size: "<<deviceProp.totalGlobalMem<<std::endl;
        std::cout<<"Max Constant memory size: "<<deviceProp.totalConstMem<<std::endl;
        std::cout<<"Max Shared memory size per block: "<<deviceProp.sharedMemPerBlock<<std::endl;
        std::cout<<"Max threads per block: "<<deviceProp.maxThreadsPerBlock<<std::endl;
        std::cout<<"Max block dimensions: "<<deviceProp.maxThreadsDim[0]<<" x, "<<deviceProp.maxThreadsDim[1]<<" y, "<<deviceProp.maxThreadsDim[2]<<" z"<<std::endl;
        std::cout<<"Max grid dimensions: "<<deviceProp.maxGridSize[0]<<" x, "<<deviceProp.maxGridSize[1]<<" y, "<<deviceProp.maxGridSize[2]<<" z"<<std::endl;
        std::cout<<"Warp Size: "<<deviceProp.warpSize<<std::endl;
    }
}
